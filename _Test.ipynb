{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 15:53:02,356 ERROR broadcast.TorrentBroadcast: Store broadcast broadcast_11146 fail, remove all pieces of the broadcast\n"
     ]
    }
   ],
   "source": [
    "from _Setting import StockSetting\n",
    "import tushare  as ts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"_Spark_T01\") \\\n",
    "        .master(\"yarn\") \\\n",
    "        .config('spark.submit.pyFiles', 'file:///work/dev/stock/_Setting.py') \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "settings = StockSetting() \n",
    "pro = ts.pro_api(settings.tushareKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def getdailydata(item):\n",
    "    dailypath = settings.datasource_daily_path+item.ts_code\n",
    "    daily_data = spark.read.format(\"json\").load(dailypath)\n",
    "    return daily_data\n",
    "\n",
    "def getdaily_basicdata(item):\n",
    "    dailypath = settings.datasource_daily_basic_path+item.ts_code\n",
    "    daily_data = spark.read.format(\"json\").load(dailypath)\n",
    "    return daily_data\n",
    "\n",
    "def getmoneyflowdata(item):\n",
    "    dailypath = settings.datasource_moneyflow_path+item.ts_code\n",
    "    daily_data = spark.read.format(\"json\").load(dailypath)\n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "99\n",
      "149\n",
      "199\n",
      "249\n",
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12 15:48:48,720 - root - ERROR - KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     daily_basic_data \u001b[39m=\u001b[39m return_value\n\u001b[1;32m     30\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[0;32m---> 31\u001b[0m     daily_basic_data \u001b[39m=\u001b[39m daily_basic_data\u001b[39m.\u001b[39;49munionAll(return_value)\n\u001b[1;32m     33\u001b[0m return_value \u001b[39m=\u001b[39m getmoneyflowdata(item)\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m(daily_moneyflow_data \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1856\u001b[0m, in \u001b[0;36mDataFrame.unionAll\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1845'>1846</a>\u001b[0m \u001b[39m@since\u001b[39m(\u001b[39m1.3\u001b[39m)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1846'>1847</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munionAll\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1847'>1848</a>\u001b[0m     \u001b[39m\"\"\" Return a new :class:`DataFrame` containing union of rows in this and another\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1848'>1849</a>\u001b[0m \u001b[39m    :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1849'>1850</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1853'>1854</a>\u001b[0m \u001b[39m    Also as standard in SQL, this function resolves columns by position (not by name).\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1854'>1855</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1855'>1856</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munion(other)\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1844\u001b[0m, in \u001b[0;36mDataFrame.union\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1833'>1834</a>\u001b[0m \u001b[39m@since\u001b[39m(\u001b[39m2.0\u001b[39m)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1834'>1835</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munion\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1835'>1836</a>\u001b[0m     \u001b[39m\"\"\" Return a new :class:`DataFrame` containing union of rows in this and another\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1836'>1837</a>\u001b[0m \u001b[39m    :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1837'>1838</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1841'>1842</a>\u001b[0m \u001b[39m    Also as standard in SQL, this function resolves columns by position (not by name).\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1842'>1843</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1843'>1844</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49munion(other\u001b[39m.\u001b[39;49m_jdf), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1312'>1313</a>\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1035'>1036</a>\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1036'>1037</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1037'>1038</a>\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1038'>1039</a>\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1039'>1040</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=472'>473</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=473'>474</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=474'>475</a>\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=475'>476</a>\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=476'>477</a>\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=477'>478</a>\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=666'>667</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=667'>668</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=668'>669</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=669'>670</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=670'>671</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "savepath = settings.datasource_path+\"stock_basic_main\"\n",
    "\n",
    "data_base_main = spark.read.format(\"json\").load(savepath)\n",
    "\n",
    "\n",
    "daily_data = None\n",
    "daily_basic_data = None\n",
    "daily_moneyflow_data = None\n",
    "x = data_base_main.collect()\n",
    "index = 0\n",
    "for item in x:\n",
    "    index = index+1\n",
    "    if(index< 1000 ):\n",
    "        if(index % 50 == 49 ):\n",
    "            print(index)\n",
    "        try:\n",
    "            return_value = getdailydata(item)\n",
    "            if(daily_data == None):\n",
    "                daily_data = return_value\n",
    "            else :\n",
    "                daily_data = daily_data.unionAll(return_value)\n",
    "\n",
    "            return_value = getdaily_basicdata(item)\n",
    "            if('dv_ratio' in return_value.columns):\n",
    "                return_value = return_value.drop('dv_ratio')\n",
    "            if('dv_ttm' in return_value.columns):\n",
    "                return_value = return_value.drop('dv_ttm')\n",
    "            if(daily_basic_data == None): \n",
    "                daily_basic_data = return_value\n",
    "            else :\n",
    "                daily_basic_data = daily_basic_data.unionAll(return_value)\n",
    "\n",
    "            return_value = getmoneyflowdata(item)\n",
    "            if(daily_moneyflow_data == None):\n",
    "                daily_moneyflow_data = return_value\n",
    "            else :\n",
    "                daily_moneyflow_data = daily_moneyflow_data.unionAll(return_value)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "print(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12 15:50:33,204 - root - ERROR - KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m daily_moneyflow_data\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py:494\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=490'>491</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a bool\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=492'>493</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(truncate, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m truncate:\n\u001b[0;32m--> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=493'>494</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mshowString(n, \u001b[39m20\u001b[39;49m, vertical))\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=494'>495</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=495'>496</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1312'>1313</a>\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1035'>1036</a>\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1036'>1037</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1037'>1038</a>\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1038'>1039</a>\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py?line=1039'>1040</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=472'>473</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=473'>474</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=474'>475</a>\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=475'>476</a>\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=476'>477</a>\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/clientserver.py?line=477'>478</a>\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=666'>667</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=667'>668</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=668'>669</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=669'>670</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///work/app/anaconda3/envs/pyspark/lib/python3.8/socket.py?line=670'>671</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "daily_moneyflow_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "savepath = settings.datasource_path+\"stock_daily_all\"\n",
    "\n",
    "daily_data_all.write.mode(\"overwrite\").format(\"json\").save(savepath)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09d5292026d74dd0d882db1b282e48d19169a513618ea22779a1255a8a058a13"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
